{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBoost\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "RANDOM_STATE = 55\n",
    "file_path=\"/Users/amangolani/Downloads/Final Data.csv\"\n",
    "\n",
    "df=pd.read_csv(file_path);\n",
    "df.drop(['Farm_ID','Irrigation_Type','Fertilizer_Used(tons)', 'Pesticide_Used(kg)','Water_Usage(cubic meters)'],axis=1,inplace=True)\n",
    "cat_var=['Soil_Type','Season']\n",
    "df=pd.get_dummies(data=df,prefix=cat_var,columns=cat_var)\n",
    "df=pd.get_dummies(data=df,prefix=['Crop_Type'],columns=['Crop_Type'])\n",
    "var = [x for x in df.columns if x not in 'Yield(tons)']\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(df[var],df['Yield(tons)'],train_size = 0.9, random_state = RANDOM_STATE)\n",
    "\n",
    "# Updated parameters for RandomForestRegressor\n",
    "random_forest_algo=RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_split=4).fit(X_train,Y_train)\n",
    "print(f\"Metrics train:\\n\\tMSE: {mean_squared_error(random_forest_algo.predict(X_train),Y_train):.4f}\\nMetrics test:\\n\\tMSE: {mean_squared_error(random_forest_algo.predict(X_test),Y_test):.4f}\")\n",
    "\n",
    "# Load augmented dataset\n",
    "file_path=\"/Users/amangolani/Downloads/augmented_agriculture_dataset_simple.csv\"\n",
    "df=pd.read_csv(file_path);\n",
    "df.drop(['Farm_ID','Irrigation_Type','Fertilizer_Used(tons)', 'Pesticide_Used(kg)','Water_Usage(cubic meters)'],axis=1,inplace=True)\n",
    "cat_var=['Soil_Type','Season']\n",
    "df=pd.get_dummies(data=df,prefix=cat_var,columns=cat_var)\n",
    "df=pd.get_dummies(data=df,prefix=['Crop_Type'],columns=['Crop_Type'])\n",
    "var = [x for x in df.columns if x not in 'Yield(tons)']\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(df[var],df['Yield(tons)'],train_size = 0.8, random_state = RANDOM_STATE)\n",
    "\n",
    "# Updated parameters for RandomForestRegressor\n",
    "random_forest_algo=RandomForestRegressor(n_estimators=200, max_depth=30, min_samples_split=5).fit(X_train,Y_train)\n",
    "print(f\"Metrics train:\\n\\tMSE: {mean_squared_error(random_forest_algo.predict(X_train),Y_train):.4f}\\nMetrics test:\\n\\tMSE: {mean_squared_error(random_forest_algo.predict(X_test),Y_test):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sdv.tabular'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msdv\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtabular\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CTGAN\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the datasets\u001b[39;00m\n\u001b[1;32m      5\u001b[0m file_paths \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/amangolani/Downloads/Final Data/AEP_hourly.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,    \u001b[38;5;66;03m# Replace with your file path if needed\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/amangolani/Downloads/Final Data/COMED_hourly.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/amangolani/Downloads/Final Data/DEOK_hourly.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m ]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sdv.tabular'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sdv.tabular import CTGAN\n",
    "\n",
    "# Load the datasets\n",
    "file_paths = [\n",
    "    '/Users/amangolani/Downloads/Final Data/AEP_hourly.csv',    # Replace with your file path if needed\n",
    "    '/Users/amangolani/Downloads/Final Data/COMED_hourly.csv',\n",
    "    '/Users/amangolani/Downloads/Final Data/DEOK_hourly.csv'\n",
    "]\n",
    "\n",
    "# Read CSV files and select the second column (ignoring datetime)\n",
    "dfs = [pd.read_csv(file).iloc[:, 1] for file in file_paths]\n",
    "\n",
    "# Merge the selected columns into a single DataFrame\n",
    "merged_df = pd.concat(dfs, axis=1)\n",
    "merged_df.columns = ['AEP', 'COMED', 'DEOK']\n",
    "\n",
    "# Fill NaN values using synthetic data\n",
    "# 1️⃣ Train CTGAN on existing (non-NaN) data\n",
    "ctgan = CTGAN()\n",
    "ctgan.fit(merged_df.dropna())\n",
    "\n",
    "# 2️⃣ Generate synthetic data for missing values\n",
    "num_missing = merged_df.isna().sum().sum()\n",
    "synthetic_data = ctgan.sample(num_missing)\n",
    "\n",
    "# 3️⃣ Fill NaN values with synthetic data\n",
    "merged_df = merged_df.fillna(pd.DataFrame(\n",
    "    synthetic_data.values[:num_missing].reshape(-1, 3),\n",
    "    columns=merged_df.columns\n",
    "))\n",
    "\n",
    "# Expand dataset to 40,000 rows\n",
    "additional_samples = 40000 - len(merged_df)\n",
    "if additional_samples > 0:\n",
    "    augmented_data = ctgan.sample(additional_samples)\n",
    "    merged_df = pd.concat([merged_df, augmented_data], ignore_index=True)\n",
    "\n",
    "# Save the final merged and augmented dataset\n",
    "merged_df.to_csv('merged_augmented_dataset.csv', index=False)\n",
    "\n",
    "print(\"✅ Dataset merged, NaNs filled, and augmented to 40,000 rows!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SequenceNotStr' from 'pandas._typing' (/Users/amangolani/anaconda3/lib/python3.11/site-packages/pandas/_typing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m     final_dataset \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Export the final dataset\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m final_dataset\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/data/final_merged_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Dataset merged, cleaned, and expanded to 40,000 entries!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3743\u001b[0m \u001b[38;5;129m@overload\u001b[39m\n\u001b[1;32m   3744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_csv\u001b[39m(\n\u001b[1;32m   3745\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3766\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3767\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   3768\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m   3770\u001b[0m \u001b[38;5;129m@overload\u001b[39m\n\u001b[1;32m   3771\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_csv\u001b[39m(\n\u001b[0;32m-> 3772\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   3773\u001b[0m     path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   3774\u001b[0m     sep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3775\u001b[0m     na_rep: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3776\u001b[0m     float_format: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m Callable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3777\u001b[0m     columns: Sequence[Hashable] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3778\u001b[0m     header: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3779\u001b[0m     index: bool_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3780\u001b[0m     index_label: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3781\u001b[0m     mode: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3782\u001b[0m     encoding: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3783\u001b[0m     compression: CompressionOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3784\u001b[0m     quoting: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3785\u001b[0m     quotechar: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3786\u001b[0m     lineterminator: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3787\u001b[0m     chunksize: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3788\u001b[0m     date_format: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3789\u001b[0m     doublequote: bool_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3790\u001b[0m     escapechar: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3791\u001b[0m     decimal: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3792\u001b[0m     errors: OpenFileErrors \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3793\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m,\n\u001b[1;32m   3794\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3795\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m   3797\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(\n\u001b[1;32m   3799\u001b[0m     version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_or_buf\u001b[39m\u001b[38;5;124m\"\u001b[39m], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   3828\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/format.py:1159\u001b[0m, in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m digits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1145\u001b[0m     digits \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay.precision\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1147\u001b[0m fmt_obj \u001b[38;5;241m=\u001b[39m fmt_klass(\n\u001b[1;32m   1148\u001b[0m     values,\n\u001b[1;32m   1149\u001b[0m     digits\u001b[38;5;241m=\u001b[39mdigits,\n\u001b[1;32m   1150\u001b[0m     na_rep\u001b[38;5;241m=\u001b[39mna_rep,\n\u001b[1;32m   1151\u001b[0m     float_format\u001b[38;5;241m=\u001b[39mfloat_format,\n\u001b[1;32m   1152\u001b[0m     formatter\u001b[38;5;241m=\u001b[39mformatter,\n\u001b[1;32m   1153\u001b[0m     space\u001b[38;5;241m=\u001b[39mspace,\n\u001b[1;32m   1154\u001b[0m     justify\u001b[38;5;241m=\u001b[39mjustify,\n\u001b[1;32m   1155\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   1156\u001b[0m     leading_space\u001b[38;5;241m=\u001b[39mleading_space,\n\u001b[1;32m   1157\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[1;32m   1158\u001b[0m     fallback_formatter\u001b[38;5;241m=\u001b[39mfallback_formatter,\n\u001b[0;32m-> 1159\u001b[0m )\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fmt_obj\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/formats/csvs.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m writers \u001b[38;5;28;01mas\u001b[39;00m libwriters\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SequenceNotStr\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache_readonly\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtypes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     ABCDatetimeIndex,\n\u001b[1;32m     29\u001b[0m     ABCIndex,\n\u001b[1;32m     30\u001b[0m     ABCMultiIndex,\n\u001b[1;32m     31\u001b[0m     ABCPeriodIndex,\n\u001b[1;32m     32\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SequenceNotStr' from 'pandas._typing' (/Users/amangolani/anaconda3/lib/python3.11/site-packages/pandas/_typing.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the datasets\n",
    "aep = pd.read_csv('/Users/amangolani/Downloads/Final Data/AEP_hourly.csv')\n",
    "comed = pd.read_csv('/Users/amangolani/Downloads/Final Data/COMED_hourly.csv')\n",
    "deok = pd.read_csv('/Users/amangolani/Downloads/Final Data/DEOK_hourly.csv')\n",
    "\n",
    "# Drop datetime columns\n",
    "aep = aep.drop(columns=['Datetime'])\n",
    "comed = comed.drop(columns=['Datetime'])\n",
    "deok = deok.drop(columns=['Datetime'])\n",
    "\n",
    "# Rename columns for clarity\n",
    "aep.columns = ['AEP_Load']\n",
    "comed.columns = ['COMED_Load']\n",
    "deok.columns = ['DEOK_Load']\n",
    "\n",
    "# Merge datasets on index\n",
    "merged_df = pd.concat([aep, comed, deok], axis=1)\n",
    "\n",
    "# Fill NaN values with random sampling from existing non-null data\n",
    "for column in merged_df.columns:\n",
    "    merged_df[column].fillna(np.random.choice(merged_df[column].dropna()), inplace=True)\n",
    "\n",
    "# Generate synthetic-like data to reach 40,000 rows\n",
    "current_size = len(merged_df)\n",
    "target_size = 40000\n",
    "\n",
    "if current_size < target_size:\n",
    "    additional_rows = merged_df.sample(target_size - current_size, replace=True).reset_index(drop=True)\n",
    "    final_dataset = pd.concat([merged_df, additional_rows], ignore_index=True)\n",
    "else:\n",
    "    final_dataset = merged_df.copy()\n",
    "\n",
    "# Export the final dataset\n",
    "final_dataset.to_csv('/mnt/data/final_merged_dataset.csv', index=False)\n",
    "\n",
    "print(\"✅ Dataset merged, cleaned, and expanded to 40,000 entries!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"household_power_consumption.csv\"\n",
    "household_data = pd.read_csv(file_path, delimiter=';', low_memory=False)\n",
    "\n",
    "# Print column names\n",
    "print(household_data.columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
